{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee02d15-dbc5-4971-b1b2-efa027bdc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60cb1d4e-1630-4e5f-b257-b302301c0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size) * std).requires_grad_()\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets == 1, 1 - predictions, predictions).mean()\n",
    "\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        # print(\"xb shape\", xb.shape)\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            # print(\"param: \", p[:8])\n",
    "            p.data -= p.grad * lr\n",
    "            p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds > 0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1fa3f0b2-48b4-468c-b780-cadc2e8b8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d841258-ec7f-41aa-afb3-c1f08833af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2648162-a8ad-40ff-a9c1-33b46f7f706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/\"train\"/\"3\").ls().sorted()\n",
    "sevens = (path/\"train\"/\"7\").ls().sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0002d640-2734-494e-8d25-7db0b0d9246d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "\n",
    "\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28 * 28)\n",
    "train_y = tensor([1] * len(threes) + [0] * len(sevens)).unsqueeze(1)\n",
    "\n",
    "\n",
    "dset = list(zip(train_x, train_y))\n",
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ca96d94-4829-472a-84f0-1addd2365e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/\"valid\"/\"3\").ls()]).float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/\"valid\"/\"7\").ls()]).float()/255\n",
    "\n",
    "\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28 * 28)\n",
    "valid_y = tensor([1] * len(valid_3_tens) + [0] * len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dataset = list(zip(valid_x, valid_y))\n",
    "\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f88da26a-fbf7-4173-be00-a845e5f2d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "params = weights,bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f2e55e6-4472-46ce-9407-5ea2c2807c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8314 0.8978 0.9315 0.9408 0.9472 0.952 0.9559 0.9589 0.9608 0.9608 0.9632 0.9647 0.9652 0.9662 0.9686 0.9701 0.9711 0.972 0.972 0.973 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
